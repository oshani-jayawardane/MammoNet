{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Simple Unet Model to Segment a Single Malignancy from Mammograms\n","\n","### Using TensorFlow Input Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["| Class               | Grayscale Value | Color Name | RGB Value        |\n","|---------------------|-----------------|------------|------------------|\n","| `background`        | `0` - 0.              | black      | `RGB (0, 0, 0)`  |\n","| `malignant_mass`    | `76` - 1.            | red        | `RGB (255, 0, 0)`|\n","| `benign_mass`       | `149` - 2.           | green      | `RGB (0, 255, 0)`|\n","| `macrocalcifications` | `178` - 3.         | cyan       | `RGB (0, 255, 255)`|\n","| `microcalcifications` | `255` - 4.         | white      | `RGB (255, 255, 255)`|\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:35.744356Z","iopub.status.busy":"2024-02-06T12:42:35.743476Z","iopub.status.idle":"2024-02-06T12:42:35.748316Z","shell.execute_reply":"2024-02-06T12:42:35.747278Z","shell.execute_reply.started":"2024-02-06T12:42:35.744321Z"},"trusted":true},"outputs":[],"source":["# %pip install focal-loss\n","# %pip install segmentation_models\n","\n","# only for error correction if using segmentation_models - of keras.utils\n","# %env SM_FRAMEWORK=tf.keras"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:35.750569Z","iopub.status.busy":"2024-02-06T12:42:35.750276Z","iopub.status.idle":"2024-02-06T12:42:35.814349Z","shell.execute_reply":"2024-02-06T12:42:35.813553Z","shell.execute_reply.started":"2024-02-06T12:42:35.750541Z"},"trusted":true},"outputs":[],"source":["# if something goes wrong with the variables - run this and clear everything\n","%reset -f"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:35.815605Z","iopub.status.busy":"2024-02-06T12:42:35.815339Z","iopub.status.idle":"2024-02-06T12:42:51.458462Z","shell.execute_reply":"2024-02-06T12:42:51.457677Z","shell.execute_reply.started":"2024-02-06T12:42:35.815582Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","print(\"Number of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","\n","strategy = tf.distribute.MirroredStrategy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:51.468308Z","iopub.status.busy":"2024-02-06T12:42:51.467934Z","iopub.status.idle":"2024-02-06T12:42:52.654519Z","shell.execute_reply":"2024-02-06T12:42:52.653766Z","shell.execute_reply.started":"2024-02-06T12:42:51.468276Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import random\n","import json\n","import time\n","\n","import sys\n","sys.path.append('../../utils')\n","sys.path.append('../../models')\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_functions = ['combined_jaccard_dice_loss', 'jaccard_loss', 'dice_loss', 'focal_loss', 'binary']\n","loss_name = loss_functions[0] \n","\n","model_name = 'attention_unet'"]},{"cell_type":"markdown","metadata":{},"source":["**Filtering Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.700434Z","iopub.status.busy":"2024-02-06T12:42:52.700102Z","iopub.status.idle":"2024-02-06T12:42:52.722359Z","shell.execute_reply":"2024-02-06T12:42:52.721401Z","shell.execute_reply.started":"2024-02-06T12:42:52.700400Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('../../data/raw/data_filtered.csv')\n","df = df[df['status'] == 'abnormal']\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.724147Z","iopub.status.busy":"2024-02-06T12:42:52.723532Z","iopub.status.idle":"2024-02-06T12:42:52.730742Z","shell.execute_reply":"2024-02-06T12:42:52.729980Z","shell.execute_reply.started":"2024-02-06T12:42:52.724115Z"},"trusted":true},"outputs":[],"source":["len(df)"]},{"cell_type":"markdown","metadata":{},"source":["Select the Appropriate Class for Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# select the required class\n","classes = ['malignant_mass', 'benign_mass', 'macrocalcifications', 'microcalcifications', 'masses']\n","selected_class = classes[0]\n","\n","if selected_class=='malignant_mass':\n","    df = df[df['m_mass'] == 1.0]\n","    mask_gray_value = 76\n","    class_name = '_mmass.png'\n","elif selected_class=='benign_mass':\n","    df = df[df['b_mass'] == 1.0]\n","    mask_gray_value = 149\n","    class_name = '_bmass.png'\n","elif selected_class=='macrocalcifications':\n","    df = df[df['macro'] == 1.0]\n","    mask_gray_value = 178\n","    class_name = '_macro.png'\n","elif selected_class=='microcalcifications':\n","    df = df[df['micro'] == 1.0]\n","    mask_gray_value = 255\n","    class_name = '_micro.png'\n","elif selected_class == 'masses':\n","    df = df[(df['m_mass'] == 1.0) | (df['b_mass'] == 1.0)]\n","    mask_gray_value = 255\n","    class_name = '_masses.png'\n","else:\n","    print('Invalid class name')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.734449Z","iopub.status.busy":"2024-02-06T12:42:52.734169Z","iopub.status.idle":"2024-02-06T12:42:52.752697Z","shell.execute_reply":"2024-02-06T12:42:52.751754Z","shell.execute_reply.started":"2024-02-06T12:42:52.734426Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.754146Z","iopub.status.busy":"2024-02-06T12:42:52.753829Z","iopub.status.idle":"2024-02-06T12:42:52.762929Z","shell.execute_reply":"2024-02-06T12:42:52.762018Z","shell.execute_reply.started":"2024-02-06T12:42:52.754116Z"},"trusted":true},"outputs":[],"source":["len(df)"]},{"cell_type":"markdown","metadata":{},"source":["**Prepare Filepaths**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.774521Z","iopub.status.busy":"2024-02-06T12:42:52.774268Z","iopub.status.idle":"2024-02-06T12:42:52.783153Z","shell.execute_reply":"2024-02-06T12:42:52.782302Z","shell.execute_reply.started":"2024-02-06T12:42:52.774498Z"},"trusted":true},"outputs":[],"source":["# most common ratio for cropped images ----- h = 1.8 * w\n","# w = 1000, h = 1800\n","# w = 1500, h = 2700\n","# w = 2000, h = 3600\n","# most common ratio for cropped images ----- h = 1.25 * w\n","# w = 1000, h = 1250\n","# w = 1500, h = 1875\n","# w = 2000, h = 2500"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.784452Z","iopub.status.busy":"2024-02-06T12:42:52.784187Z","iopub.status.idle":"2024-02-06T12:42:52.794773Z","shell.execute_reply":"2024-02-06T12:42:52.794009Z","shell.execute_reply.started":"2024-02-06T12:42:52.784430Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# if crop is not used\n","# IMAGE_HEIGHT = 4096//4\n","# IMAGE_WIDTH = 3328//4\n","\n","# if crop is used\n","IMAGE_HEIGHT = 2048//4\n","IMAGE_WIDTH = 1024//4\n","\n","# IMAGE_HEIGHT = 3200//4\n","# IMAGE_WIDTH = 1728//4\n","\n","\n","image_size = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","\n","image_dir = '../../data/raw/abnormal/images/'\n","mask_dir = '../../data/raw/abnormal/masks/'\n","\n","image_files = sorted([image_dir + id + '.png' for id in df['image_id']])\n","# mask_files = sorted([mask_dir + id + '.png' for id in df['image_id']])\n","\n","mask_files = []\n","\n","for image_id in df['image_id']:\n","    folder_path = os.path.join(mask_dir, image_id)\n","    if os.path.isdir(folder_path):\n","        for file in os.listdir(folder_path):\n","            if file.endswith(class_name):\n","                mask_files.append(os.path.join(folder_path, file))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.796421Z","iopub.status.busy":"2024-02-06T12:42:52.795830Z","iopub.status.idle":"2024-02-06T12:42:52.807367Z","shell.execute_reply":"2024-02-06T12:42:52.806477Z","shell.execute_reply.started":"2024-02-06T12:42:52.796390Z"},"trusted":true},"outputs":[],"source":["print(len(mask_files), len(image_files))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logs_directory = f'../../logs/annotation_class_pixels/{model_name}/{selected_class}/{loss_name}/'\n","os.makedirs(logs_directory, exist_ok=True)\n","\n","results_dir = f'../../results/annotation_class_pixels/{model_name}/{selected_class}/{loss_name}/'\n","os.makedirs(results_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["**Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.827175Z","iopub.status.busy":"2024-02-06T12:42:52.826892Z","iopub.status.idle":"2024-02-06T12:42:52.840559Z","shell.execute_reply":"2024-02-06T12:42:52.839618Z","shell.execute_reply.started":"2024-02-06T12:42:52.827152Z"},"trusted":true},"outputs":[],"source":["from preprocessing import crop_breast, dilate, truncate, clahe\n","\n","def preprocessing_pipeline(img, mask):\n","    image, mask, new_height, new_width = crop_breast(img.numpy().squeeze(), mask.numpy().squeeze())\n","    # image = truncate(image, lower_percentile=20, upper_percentile=100)\n","    # image = dilate(image, kernel_size=3, iterations=1)\n","    image = clahe(image, clip=1.0, gridSize=20)\n","    \n","    image = image.reshape(new_height, new_width, 1)\n","    mask = mask.reshape(new_height, new_width, 1)\n","    \n","    img_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n","    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n","    \n","    return img_tensor, mask_tensor\n","\n","\n","def wrap_preprocessing(image, mask):\n","    processed_image, processed_mask = tf.py_function(\n","        preprocessing_pipeline,\n","        [image, mask],\n","        [tf.float32, tf.float32]\n","    )\n","    \n","    processed_image.set_shape([None, None, 1])\n","    processed_mask.set_shape([None, None, 1])\n","    \n","    return processed_image, processed_mask"]},{"cell_type":"markdown","metadata":{},"source":["**Prepare Data**"]},{"cell_type":"markdown","metadata":{},"source":["Change the target_class as necessary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.882003Z","iopub.status.busy":"2024-02-06T12:42:52.881652Z","iopub.status.idle":"2024-02-06T12:42:52.886876Z","shell.execute_reply":"2024-02-06T12:42:52.885987Z","shell.execute_reply.started":"2024-02-06T12:42:52.881968Z"},"trusted":true},"outputs":[],"source":["############################################\n","# run this code if pre-processing is not involved\n","############################################\n","\n","# def process_path(image_path, mask_path):\n","    \n","#     # Process Image\n","#     img = tf.io.read_file(image_path)\n","#     img = tf.image.decode_png(img, channels=1)\n","\n","#     # Process Mask\n","#     mask = tf.io.read_file(mask_path)\n","#     mask = tf.image.decode_png(mask, channels=1)\n","    \n","#     # Normalize - run if not preprocessing\n","#     img = img / 255  # Normalize [0, 1]\n","#     mask = mask / mask_gray_value # Normalize [0, 1]\n","    \n","#     # Resize\n","#     img = tf.image.resize(img, image_size)\n","#     mask = tf.image.resize(mask, image_size, method='nearest')\n","    \n","#     mask = tf.cast(mask, tf.int32)\n","\n","#     return img, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.888754Z","iopub.status.busy":"2024-02-06T12:42:52.888082Z","iopub.status.idle":"2024-02-06T12:42:52.900967Z","shell.execute_reply":"2024-02-06T12:42:52.900189Z","shell.execute_reply.started":"2024-02-06T12:42:52.888708Z"},"trusted":true},"outputs":[],"source":["############################################\n","# run this code if pre-processing is involved\n","############################################\n","\n","\n","def process_path(image_path, mask_path):\n","    \n","    # Process Image\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_png(img, channels=1)\n","\n","    # Process Mask\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    \n","    # Custom Preprocessing\n","    img, mask = wrap_preprocessing(img, mask)\n","    \n","    # Resize\n","    img = tf.image.resize(img, image_size)\n","    mask = tf.image.resize(mask, image_size, method='nearest')\n","    \n","    # Normalize\n","    img = img / 255  # Normalize [0, 1]\n","    mask = mask / mask_gray_value # Normalize [0, 1]\n","    \n","    mask = tf.cast(mask, tf.int32)\n","\n","    return img, mask"]},{"cell_type":"markdown","metadata":{},"source":["**Train and Test Split**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.902292Z","iopub.status.busy":"2024-02-06T12:42:52.902014Z","iopub.status.idle":"2024-02-06T12:42:52.915557Z","shell.execute_reply":"2024-02-06T12:42:52.914850Z","shell.execute_reply.started":"2024-02-06T12:42:52.902269Z"},"trusted":true},"outputs":[],"source":["image_files_unseen = image_files[-1]\n","mask_files_unseen = mask_files[-1]\n","\n","image_files = image_files[:-1]\n","mask_files = mask_files[:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.917409Z","iopub.status.busy":"2024-02-06T12:42:52.916633Z","iopub.status.idle":"2024-02-06T12:42:52.928323Z","shell.execute_reply":"2024-02-06T12:42:52.927461Z","shell.execute_reply.started":"2024-02-06T12:42:52.917385Z"},"trusted":true},"outputs":[],"source":["train_images, test_images, train_masks, test_masks = train_test_split(image_files, mask_files, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.929588Z","iopub.status.busy":"2024-02-06T12:42:52.929281Z","iopub.status.idle":"2024-02-06T12:42:52.937083Z","shell.execute_reply":"2024-02-06T12:42:52.936168Z","shell.execute_reply.started":"2024-02-06T12:42:52.929557Z"},"trusted":true},"outputs":[],"source":["print(f\"Number of training images: {len(train_images)}\")\n","print(f\"Number of training masks: {len(train_masks)}\")\n","print(f\"Number of testing images: {len(test_images)}\")\n","print(f\"Number of testing masks: {len(test_masks)}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Build Data pipeline**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def augment(image, mask):\n","    if tf.random.uniform([]) < 0.5:\n","        image = tf.image.random_flip_left_right(image)\n","        mask = tf.image.random_flip_left_right(mask)\n","\n","    if tf.random.uniform([]) < 0.5:\n","        image = tf.image.random_brightness(image, max_delta=0.1)\n","\n","    if tf.random.uniform([]) < 0.5:\n","        image = tf.image.random_contrast(image, lower=0.2, upper=0.5)\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:52.938338Z","iopub.status.busy":"2024-02-06T12:42:52.938069Z","iopub.status.idle":"2024-02-06T12:42:53.191459Z","shell.execute_reply":"2024-02-06T12:42:53.190756Z","shell.execute_reply.started":"2024-02-06T12:42:52.938315Z"},"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks))\n","\n","batch_size = 8\n","prefetch_buffer_size=tf.data.AUTOTUNE\n","\n","train_dataset = train_dataset.map(process_path)\n","train_dataset = train_dataset.cache(filename='cached_train_data.tfrecord')\n","train_dataset = train_dataset.map(augment).batch(batch_size).prefetch(prefetch_buffer_size)\n","\n","test_dataset = test_dataset.map(process_path).cache(filename='cached_test_data.tfrecord').batch(batch_size).prefetch(prefetch_buffer_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:42:53.196226Z","iopub.status.busy":"2024-02-06T12:42:53.195955Z","iopub.status.idle":"2024-02-06T12:43:02.700807Z","shell.execute_reply":"2024-02-06T12:43:02.699880Z","shell.execute_reply.started":"2024-02-06T12:42:53.196198Z"},"trusted":true},"outputs":[],"source":["# Sanity check\n","\n","for images, masks in train_dataset.take(1):\n","    print(\"Image batch shape:\", images.shape)\n","    print(\"Image batch dtype:\", images.dtype)\n","    print(\"Mask batch shape:\", masks.shape)\n","    print(\"Mask batch dtype:\", masks.dtype)\n","\n","gc.collect()    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:02.702866Z","iopub.status.busy":"2024-02-06T12:43:02.702159Z","iopub.status.idle":"2024-02-06T12:43:02.710269Z","shell.execute_reply":"2024-02-06T12:43:02.709254Z","shell.execute_reply.started":"2024-02-06T12:43:02.702827Z"},"trusted":true},"outputs":[],"source":["# do sanity check - view image and mask randomly\n","\n","def show_img_mask(dataset, batch, image_number):\n","    for images, masks in train_dataset.take(batch):\n","        \n","        image = images[image_number]\n","        mask = masks[image_number]\n","\n","        plt.figure(figsize=(10, 5))\n","\n","        plt.subplot(1, 2, 1)\n","        plt.imshow(tf.squeeze(image), cmap='gray')\n","        plt.title('Image')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.imshow(tf.squeeze(mask), cmap='gray')\n","        plt.title('Mask')\n","        plt.axis('off')\n","\n","        plt.show()\n","\n","        print(\"Unique values in the mask:\", np.unique(tf.squeeze(mask).numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:02.711582Z","iopub.status.busy":"2024-02-06T12:43:02.711323Z","iopub.status.idle":"2024-02-06T12:43:20.454576Z","shell.execute_reply":"2024-02-06T12:43:20.453673Z","shell.execute_reply.started":"2024-02-06T12:43:02.711560Z"},"trusted":true},"outputs":[],"source":["show_img_mask(dataset=train_dataset, batch=3, image_number=2)"]},{"cell_type":"markdown","metadata":{},"source":["### **Define the Unet Model**"]},{"cell_type":"markdown","metadata":{},"source":["Simple Unet model for single-class segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:20.456238Z","iopub.status.busy":"2024-02-06T12:43:20.455937Z","iopub.status.idle":"2024-02-06T12:43:20.470356Z","shell.execute_reply":"2024-02-06T12:43:20.469494Z","shell.execute_reply.started":"2024-02-06T12:43:20.456205Z"},"trusted":true},"outputs":[],"source":["from unet_models import unet_model, res_unet_model, VGG16_UNet, attention_unet_model, attention_res_unet_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_model(model_name):\n","    input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n","    \n","    if model_name == 'simple_unet':\n","        return unet_model(num_classes=1, input_size=input_shape, num_filters=64, dropout=0.1, batch_norm=False)\n","    elif model_name == 'simple_resunet':\n","        return res_unet_model(num_classes=1, input_size=input_shape, num_filters=64, dropout=0.1, batch_norm=False)\n","    elif model_name == 'vgg_tl_unet': \n","        return VGG16_UNet(num_classes=1, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), dropout=0.1, batch_norm=False) # VGG requires 3 channels\n","    elif model_name == 'attention_unet':\n","        return attention_unet_model(num_classes=1, input_size=input_shape, num_filters=64, dropout=0.1, batch_norm=False)\n","    elif model_name == 'attention_resunet':\n","        return attention_res_unet_model(num_classes=1, input_size=input_shape, num_filters=64, dropout=0.1, batch_norm=False)\n","    else:\n","        raise ValueError(\"Unknown model name\")"]},{"cell_type":"markdown","metadata":{},"source":["**Compile Model**"]},{"cell_type":"markdown","metadata":{},"source":["test with \n","* different optimizers - adam, rmsprop, sgd\n","* loss functions - binary_crossentropy, iou/jaccard loss, dice loss, combined iou and dice loss, focal loss\n","* metrics - iou/jaccard, dice coefficient, Fscore"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:20.523103Z","iopub.status.busy":"2024-02-06T12:43:20.522867Z","iopub.status.idle":"2024-02-06T12:43:21.829599Z","shell.execute_reply":"2024-02-06T12:43:21.828763Z","shell.execute_reply.started":"2024-02-06T12:43:20.523082Z"},"trusted":true},"outputs":[],"source":["from loss_and_metrics import jaccard_coef, jaccard_loss, dice_coef, dice_loss, combined_jaccard_dice_loss, focal_loss, specificity, precision, recall, f1score\n","\n","with strategy.scope():\n","    model = get_model(model_name)\n","    \n","    metrics = ['accuracy', f1score, specificity, jaccard_coef, dice_coef]\n","    \n","    if loss_name == 'combined_jaccard_dice_loss':\n","        loss_function = combined_jaccard_dice_loss(alpha=0.5)\n","    elif loss_name == 'jaccard_loss':\n","        loss_function = jaccard_loss\n","    elif loss_name == 'dice_loss':\n","        loss_function = dice_loss\n","    elif loss_name == 'focal_loss':\n","        loss_function = focal_loss\n","    elif loss_name == 'binary':\n","        loss_function = 'binary_crossentropy'\n","    else:\n","        raise ValueError('Invalid loss function')\n","\n","    model.compile(optimizer=Adam(lr=1e-5), loss=loss_function, metrics=metrics)\n","\n","    model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["**Train the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:21.831484Z","iopub.status.busy":"2024-02-06T12:43:21.831116Z","iopub.status.idle":"2024-02-06T12:43:21.838310Z","shell.execute_reply":"2024-02-06T12:43:21.837438Z","shell.execute_reply.started":"2024-02-06T12:43:21.831447Z"},"trusted":true},"outputs":[],"source":["checkpoint_path = logs_directory + '{}_best.hdf5'.format(model_name)\n","model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n","                                   monitor='val_loss', \n","                                   verbose=1, \n","                                   save_best_only=True, \n","                                   save_weights_only=False, \n","                                   mode='min')\n","\n","early_stopping = EarlyStopping(monitor='val_loss', \n","                               patience=7, \n","                               verbose=1, \n","                               mode='min')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T12:43:21.840286Z","iopub.status.busy":"2024-02-06T12:43:21.839503Z","iopub.status.idle":"2024-02-06T13:06:21.403303Z","shell.execute_reply":"2024-02-06T13:06:21.402484Z","shell.execute_reply.started":"2024-02-06T12:43:21.840260Z"},"trusted":true},"outputs":[],"source":["# If starting with pre-trained weights. \n","# model.load_weights('???.hdf5')\n","\n","epochs = 150\n","\n","start_time = time.time()\n","\n","history = model.fit(train_dataset, \n","                    epochs=epochs, \n","                    validation_data=test_dataset, \n","                    verbose=1, \n","                    shuffle=False,\n","                    callbacks=[model_checkpoint, early_stopping]\n","                   )\n","\n","end_time = time.time()\n","\n","training_time = end_time - start_time\n","\n","model.save(logs_directory + '{}.hdf5'.format(model_name))\n","\n","history_file = results_dir + '{}_history.json'.format(model_name)\n","\n","with open(history_file, 'w') as f:\n","    json.dump(history.history, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Training time: {training_time} seconds\")"]},{"cell_type":"markdown","metadata":{},"source":["### **Evaluations**"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy and Loss**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:21.424126Z","iopub.status.busy":"2024-02-06T13:06:21.423817Z","iopub.status.idle":"2024-02-06T13:06:24.000623Z","shell.execute_reply":"2024-02-06T13:06:23.999688Z","shell.execute_reply.started":"2024-02-06T13:06:21.424099Z"},"trusted":true},"outputs":[],"source":["loss_val, acc, f1, spec, iou, dice = model.evaluate(test_dataset)\n","\n","content = f\"\"\"\n","Loss: {loss_val}\n","Accuracy: {acc}\n","F1-Score: {f1}\n","Specificity: {spec}\n","IoU / Jaccard Coeff: {iou}\n","Dice Coeff: {dice}\n","\"\"\"\n","\n","print(content)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:24.002259Z","iopub.status.busy":"2024-02-06T13:06:24.001895Z","iopub.status.idle":"2024-02-06T13:06:24.614451Z","shell.execute_reply":"2024-02-06T13:06:24.613536Z","shell.execute_reply.started":"2024-02-06T13:06:24.002224Z"},"trusted":true},"outputs":[],"source":["#plot the training and validation accuracy and loss at each epoch\n","\n","fig, axs = plt.subplots(1, 4, figsize=(20, 8))\n","\n","# Plot the training and validation loss\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","axs[0].plot(epochs, loss, 'y', label='Training loss')\n","axs[0].plot(epochs, val_loss, 'r', label='Validation loss')\n","axs[0].set_title('Training and validation loss')\n","axs[0].set_xlabel('Epochs')\n","axs[0].set_ylabel('Loss')\n","axs[0].legend()\n","\n","# Plot the training and validation Jaccard Coef\n","jc = history.history['jaccard_coef']\n","val_jc = history.history['val_jaccard_coef']\n","axs[1].plot(epochs, jc, 'y', label='Training Jacard Coeff.')\n","axs[1].plot(epochs, val_jc, 'r', label='Validation Jacard Coeff.')\n","axs[1].set_title('Training and validation Jacard')\n","axs[1].set_xlabel('Epochs')\n","axs[1].set_ylabel('Jacard Coefficient')\n","axs[1].legend()\n","\n","dice = history.history['dice_coef']\n","val_dice = history.history['val_dice_coef']\n","axs[2].plot(epochs, dice, 'y', label='Training Dice Coeff.')\n","axs[2].plot(epochs, val_dice, 'r', label='Validation Dice Coeff.')\n","axs[2].set_title('Training and validation Dice')\n","axs[2].set_xlabel('Epochs')\n","axs[2].set_ylabel('Dice Coefficient')\n","axs[2].legend()\n","\n","fs = history.history['f1score']\n","val_fs = history.history['val_f1score']\n","axs[3].plot(epochs, fs, 'y', label='F1score')\n","axs[3].plot(epochs, val_fs, 'r', label='F1score')\n","axs[3].set_title('Training and validation F1score')\n","axs[3].set_xlabel('Epochs')\n","axs[3].set_ylabel('F1score')\n","axs[3].legend()\n","\n","plt.show()\n","\n","fig.savefig(os.path.join(results_dir, 'training_validation_metrics.png'))"]},{"cell_type":"markdown","metadata":{},"source":["**Best Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:24.615911Z","iopub.status.busy":"2024-02-06T13:06:24.615591Z","iopub.status.idle":"2024-02-06T13:06:24.619676Z","shell.execute_reply":"2024-02-06T13:06:24.618711Z","shell.execute_reply.started":"2024-02-06T13:06:24.615884Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","model = load_model(checkpoint_path, compile=False)  \n","\n","model.compile(optimizer=Adam(lr=1e-5), loss=loss_function, metrics=metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, accuracy, f1score, specificity, iou, dice = model.evaluate(test_dataset)\n","\n","content = f\"\"\"\n","---------------------------------------------\n","Model: {model_name}\n","---------------------------------------------\n","Loss Function: {loss_name}\n","\n","Training completed in: {training_time} seconds\n","\n","Loss: {loss}\n","Accuracy: {accuracy}\n","F1-Score: {f1score}\n","Specificity: {specificity}\n","IoU / Jaccard Coeff: {iou}\n","Dice Coeff: {dice}\n","\"\"\"\n","\n","print(content)\n","\n","filename = os.path.join(results_dir, 'model_evaluation_results.txt')\n","\n","with open(filename, 'w') as file:\n","    file.write(content)\n","\n","print(\"The evaluation metrics have been saved to:\", filename)"]},{"cell_type":"markdown","metadata":{},"source":["**Average IoU Score**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["threshold=0.7"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:24.621009Z","iopub.status.busy":"2024-02-06T13:06:24.620747Z","iopub.status.idle":"2024-02-06T13:06:24.631866Z","shell.execute_reply":"2024-02-06T13:06:24.631052Z","shell.execute_reply.started":"2024-02-06T13:06:24.620985Z"},"trusted":true},"outputs":[],"source":["def calculate_iou_per_image(y_true, y_pred):\n","\n","    intersection = np.logical_and(y_true, y_pred > threshold).sum()\n","    union = np.logical_or(y_true, y_pred).sum()\n","    if union == 0:\n","        return float('nan')  # Avoid division by zero; handle as you see fit\n","    else:\n","        return intersection / union"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:24.633042Z","iopub.status.busy":"2024-02-06T13:06:24.632814Z","iopub.status.idle":"2024-02-06T13:06:30.441995Z","shell.execute_reply":"2024-02-06T13:06:30.441087Z","shell.execute_reply.started":"2024-02-06T13:06:24.633022Z"},"trusted":true},"outputs":[],"source":["def calculate_mean_iou(test_dataset, model):\n","\n","    ious = []\n","    for images, true_masks in test_dataset:\n","        pred_masks = model.predict(images)\n","        for i in range(images.shape[0]):  # Iterate through the batch\n","            iou = calculate_iou_per_image(true_masks[i].numpy(), (pred_masks[i] > 0.5).astype(int))\n","            if not np.isnan(iou):\n","                ious.append(iou)\n","    \n","    return np.nanmean(ious)\n","\n","mean_iou = calculate_mean_iou(test_dataset, model)\n","\n","mean_iou_content = f\"Mean IoU = {mean_iou}\"\n","\n","print(mean_iou_content)\n","\n","with open(filename, 'a') as file:\n","    file.write('\\n' + mean_iou_content)\n","\n","print(\"Mean IoU has been added to:\", filename)"]},{"cell_type":"markdown","metadata":{},"source":["Area Under Curve"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_true = []\n","y_pred = []\n","\n","for images, masks in test_dataset:\n","    predictions = model.predict(images)\n","    perdictions = predictions > threshold\n","    y_pred.extend(predictions.flatten())\n","    y_true.extend(masks.numpy().flatten())\n","\n","y_true = tf.convert_to_tensor(y_true)\n","y_pred = tf.convert_to_tensor(y_pred)\n","\n","auc = tf.keras.metrics.AUC()\n","auc.update_state(y_true, y_pred)\n","auc_result = auc.result().numpy()\n","\n","auc_result_content = f'AUC = {auc_result}'\n","print(auc_result_content)\n","\n","with open(filename, 'a') as file:\n","    file.write('\\n' + auc_result_content)\n","\n","print(\"AUC has been added to:\", filename)"]},{"cell_type":"markdown","metadata":{},"source":["**Confusion Matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:06:30.443295Z","iopub.status.busy":"2024-02-06T13:06:30.443033Z","iopub.status.idle":"2024-02-06T13:09:05.906889Z","shell.execute_reply":"2024-02-06T13:09:05.905928Z","shell.execute_reply.started":"2024-02-06T13:06:30.443273Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","all_true_labels = []\n","all_predicted_labels = []\n","\n","for images, masks in test_dataset:\n","    y_pred = model.predict(images)\n","    \n","    # y_pred = tf.math.round(y_pred)  # convert pred probs to binary preds (0 or 1)\n","    y_pred = tf.cast(y_pred > threshold, tf.float32)\n","    y_true = tf.cast(masks, tf.float32)\n","    \n","    all_predicted_labels.extend(y_pred.numpy().flatten())\n","    all_true_labels.extend(y_true.numpy().flatten())\n","    \n","    del y_pred, y_true\n","    gc.collect()\n","\n","cm = confusion_matrix(all_true_labels, all_predicted_labels)\n","\n","plt.figure(figsize=(6, 4))\n","\n","class_names = ['Background', 'Lesion']\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","plt.title('Confusion Matrix')\n","plt.ylabel('Actual Class')\n","plt.xlabel('Predicted Class')\n","\n","plt.savefig(os.path.join(results_dir, 'confusion_matrix.png'))\n","plt.show()\n","plt.clf()"]},{"cell_type":"markdown","metadata":{},"source":["## **Predictions**"]},{"cell_type":"markdown","metadata":{},"source":["**Predict on Test Image**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:09:05.908795Z","iopub.status.busy":"2024-02-06T13:09:05.908275Z","iopub.status.idle":"2024-02-06T13:09:07.271581Z","shell.execute_reply":"2024-02-06T13:09:07.270745Z","shell.execute_reply.started":"2024-02-06T13:09:05.908764Z"},"trusted":true},"outputs":[],"source":["def check_predictions(dataset, batch, img):\n","    for images, masks in dataset.take(batch):\n","\n","        predicted_masks = model.predict(images)\n","\n","        # predicted_masks = tf.math.round(predicted_masks)\n","        predicted_masks = tf.cast(predicted_masks > threshold, tf.float32)\n","\n","        true_masks = tf.cast(masks, tf.float32)\n","        \n","        iou = calculate_iou_per_image(true_masks[img], predicted_masks[img])\n","\n","        plt.figure(figsize=(15, 5))\n","        plt.subplot(131)\n","        plt.imshow(images[img])\n","        plt.title(\"Original Image\")\n","\n","        plt.subplot(132)\n","        plt.imshow(true_masks[img], cmap='jet')\n","        plt.title(\"Ground Truth\")\n","\n","        plt.subplot(133)\n","        plt.imshow(predicted_masks[img], cmap='jet')\n","        plt.title(f\"Predicted Image = IoU: {iou:.4f}\")\n","        \n","        plt.savefig(os.path.join(results_dir, 'predictions_on_test_image.png'))\n","\n","        plt.show()\n","    \n","        plt.clf()\n","        \n","check_predictions(dataset=test_dataset, batch=2, img=3)"]},{"cell_type":"markdown","metadata":{},"source":["**Predict on Unseen Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:09:07.273028Z","iopub.status.busy":"2024-02-06T13:09:07.272726Z","iopub.status.idle":"2024-02-06T13:09:12.928846Z","shell.execute_reply":"2024-02-06T13:09:12.927909Z","shell.execute_reply.started":"2024-02-06T13:09:07.273002Z"},"trusted":true},"outputs":[],"source":["def predict_single_image_mask(model, image_path, mask_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_image(image, channels=1)\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    image, mask = wrap_preprocessing(image, mask)\n","    image = tf.image.resize(image, image_size)\n","    image = image / 255\n","    mask = tf.image.resize(mask, image_size, method='nearest')\n","    mask = tf.math.round(mask / mask_gray_value)\n","    \n","    image = tf.expand_dims(image, axis=0)\n","    mask = tf.expand_dims(mask, axis=0)\n","    \n","    predicted_mask = model.predict(image)\n","    \n","    # predicted_mask = tf.math.round(predicted_mask)\n","    predicted_mask = tf.cast(predicted_mask > threshold, tf.float32)\n","    iou = calculate_iou_per_image(mask, predicted_mask)\n","\n","    plt.figure(figsize=(15, 5))\n","    plt.subplot(131)\n","    plt.imshow(image[0])\n","    plt.title(\"Original Image\")\n","\n","    plt.subplot(132)\n","    plt.imshow(mask[0], cmap='jet')\n","    plt.title(\"Ground Truth\")\n","\n","    plt.subplot(133)\n","    plt.imshow(predicted_mask[0], cmap='jet')\n","    plt.title(f\"Predicted Image - IoU: {iou:.4f}\")\n","    \n","    plt.savefig(os.path.join(results_dir, 'predictions_on_unseen_image.png'))\n","    \n","    plt.show()\n","    \n","    plt.clf()\n","    \n","predict_single_image_mask(model, image_files_unseen, mask_files_unseen)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T13:09:12.930577Z","iopub.status.busy":"2024-02-06T13:09:12.930228Z","iopub.status.idle":"2024-02-06T13:09:15.035134Z","shell.execute_reply":"2024-02-06T13:09:15.034189Z","shell.execute_reply.started":"2024-02-06T13:09:12.930545Z"},"trusted":true},"outputs":[],"source":["# def predict_single_image(model, image_path):\n","#     image = tf.io.read_file(image_path)\n","#     image = tf.image.decode_image(image, channels=1)\n","#     image, _ = wrap_preprocessing(image, np.zeros(image.shape))\n","#     image = tf.image.resize(image, image_size)\n","#     image = image / 255\n","    \n","#     image = tf.expand_dims(image, axis=0)\n","    \n","#     predicted_mask = model.predict(image)\n","    \n","#     predicted_mask = tf.math.round(predicted_mask)\n","    \n","#     plt.figure(figsize=(10, 5))\n","#     plt.subplot(121)\n","#     plt.imshow(image[0])\n","#     plt.title(\"Original Image\")\n","    \n","#     plt.subplot(122)\n","#     plt.imshow(predicted_mask[0], cmap='jet')\n","#     plt.title(\"Predicted Image\")\n","    \n","#     plt.show()\n","\n","# image_path = '/kaggle/input/unseen/0248-LCC.png'\n","# predict_single_image(model, image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4359338,"sourceId":7487757,"sourceType":"datasetVersion"},{"datasetId":4310623,"sourceId":7566978,"sourceType":"datasetVersion"},{"sourceId":161257104,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":4}
